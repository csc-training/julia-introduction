{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# High performance computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Topics\n",
    "- Why Julia is fast\n",
    "- LLVM compiler\n",
    "- Parallellization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is Julia fast?\n",
    "- Rich type information, provided naturally by multiple dispatch\n",
    "- Aggressive code specialization against run-time types\n",
    "- JIT compilation using the LLVM compiler framework\n",
    "\n",
    "In short, Julia is designated from the beginning to be fast. Not vice versa.\n",
    "\n",
    "See the [scientific paper](https://arxiv.org/pdf/1209.5145v1.pdf) behind Julia, if you want to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Levels of parallellism\n",
    "1. Instruction level parallellism\n",
    "2. Vector instructions (see `Bonus_simd-vectorization.pynb` if you are interested)\n",
    "3. **Threading** (shared-memory)\n",
    "4. **Distributed**\n",
    "5. Accelerators (e.g., GPGPU; *not covered here*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advanced: A (very short) introduction to the interiors of Julia compiler\n",
    "\n",
    "Let's stop treating our tools like blackboxes. Let's see what the compiler herself is thinking about our code.\n",
    "\n",
    "1. `@code_lowered`\n",
    "2. `@code_typed` and `@code_warntype`\n",
    "3. `@code_llvm`\n",
    "4. `@code_native`\n",
    "\n",
    "See [slides](https://slides.com/valentinchuravy/julia-parallelism) by Valentin Churavy, for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(A)\n",
    "    acc = zero(eltype(A))\n",
    "    for a in A\n",
    "        acc += a\n",
    "    end\n",
    "    return acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(:(begin \n",
       "        nothing\n",
       "        acc = (Main.zero)((Main.eltype)(A)) # line 3:\n",
       "        SSAValue(0) = A\n",
       "        #temp# = (Base.start)(SSAValue(0))\n",
       "        6: \n",
       "        unless !((Base.done)(SSAValue(0), #temp#)) goto 15\n",
       "        SSAValue(1) = (Base.next)(SSAValue(0), #temp#)\n",
       "        a = (Core.getfield)(SSAValue(1), 1)\n",
       "        #temp# = (Core.getfield)(SSAValue(1), 2) # line 4:\n",
       "        acc = acc + a\n",
       "        13: \n",
       "        goto 6\n",
       "        15:  # line 6:\n",
       "        return acc\n",
       "    end))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@code_lowered mysum(ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(:(begin \n",
       "        acc = (Base.sitofp)(Float64, 0)::Float64 # line 3:\n",
       "        #temp# = 1\n",
       "        4: \n",
       "        unless (Base.not_int)((#temp# === (Base.add_int)((Base.arraylen)(A)::Int64, 1)::Int64)::Bool)::Bool goto 14\n",
       "        SSAValue(2) = (Base.arrayref)(A, #temp#)::Float64\n",
       "        SSAValue(3) = (Base.add_int)(#temp#, 1)::Int64\n",
       "        a = SSAValue(2)\n",
       "        #temp# = SSAValue(3) # line 4:\n",
       "        acc = (Base.add_float)(acc, a)::Float64\n",
       "        12: \n",
       "        goto 4\n",
       "        14:  # line 6:\n",
       "        return acc\n",
       "    end))=>Float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@code_typed mysum(ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "define double @julia_mysum_63268(i8** dereferenceable(40)) #0 !dbg !5 {\n",
      "top:\n",
      "  %1 = getelementptr inbounds i8*, i8** %0, i64 1\n",
      "  %2 = bitcast i8** %1 to i64*\n",
      "  %3 = load i64, i64* %2, align 8\n",
      "  %4 = icmp eq i64 %3, 0\n",
      "  br i1 %4, label %L14, label %if.lr.ph\n",
      "\n",
      "if.lr.ph:                                         ; preds = %top\n",
      "  %5 = getelementptr i8*, i8** %0, i64 3\n",
      "  %6 = bitcast i8** %5 to i64*\n",
      "  %7 = load i64, i64* %6, align 8\n",
      "  %8 = bitcast i8** %0 to double**\n",
      "  %9 = load double*, double** %8, align 8\n",
      "  br label %if\n",
      "\n",
      "if:                                               ; preds = %if.lr.ph, %idxend\n",
      "  %acc.06 = phi double [ 0.000000e+00, %if.lr.ph ], [ %16, %idxend ]\n",
      "  %\"#temp#.05\" = phi i64 [ 1, %if.lr.ph ], [ %15, %idxend ]\n",
      "  %10 = add i64 %\"#temp#.05\", -1\n",
      "  %11 = icmp ult i64 %10, %7\n",
      "  br i1 %11, label %idxend, label %oob\n",
      "\n",
      "L14.loopexit:                                     ; preds = %idxend\n",
      "  br label %L14\n",
      "\n",
      "L14:                                              ; preds = %L14.loopexit, %top\n",
      "  %acc.0.lcssa = phi double [ 0.000000e+00, %top ], [ %16, %L14.loopexit ]\n",
      "  ret double %acc.0.lcssa\n",
      "\n",
      "oob:                                              ; preds = %if\n",
      "  %12 = alloca i64, align 8\n",
      "  store i64 %\"#temp#.05\", i64* %12, align 8\n",
      "  call void @jl_bounds_error_ints(i8** nonnull %0, i64* nonnull %12, i64 1)\n",
      "  unreachable\n",
      "\n",
      "idxend:                                           ; preds = %if\n",
      "  %13 = getelementptr double, double* %9, i64 %10\n",
      "  %14 = load double, double* %13, align 8\n",
      "  %15 = add i64 %\"#temp#.05\", 1\n",
      "  %16 = fadd double %acc.06, %14\n",
      "  %17 = icmp eq i64 %\"#temp#.05\", %3\n",
      "  br i1 %17, label %L14.loopexit, label %if\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm mysum(ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.section\t__TEXT,__text,regular,pure_instructions\n",
      "Filename: In[9]\n",
      "Source line: 3\n",
      "\tmovq\t8(%rdi), %rax\n",
      "\txorpd\t%xmm0, %xmm0\n",
      "\ttestq\t%rax, %rax\n",
      "\tje\tL50\n",
      "\tmovq\t(%rdi), %rdx\n",
      "\tmovq\t24(%rdi), %rsi\n",
      "\txorpd\t%xmm0, %xmm0\n",
      "\txorl\t%ecx, %ecx\n",
      "\tnopw\t(%rax,%rax)\n",
      "L32:\n",
      "\tcmpq\t%rsi, %rcx\n",
      "\tjae\tL51\n",
      "Source line: 4\n",
      "\taddsd\t(%rdx,%rcx,8), %xmm0\n",
      "Source line: 3\n",
      "\tincq\t%rcx\n",
      "\tcmpq\t%rcx, %rax\n",
      "\tjne\tL32\n",
      "Source line: 6\n",
      "L50:\n",
      "\tretq\n",
      "L51:\n",
      "\tpushq\t%rbp\n",
      "\tmovq\t%rsp, %rbp\n",
      "Source line: 3\n",
      "\tmovq\t%rsp, %rax\n",
      "\tleaq\t-16(%rax), %rsi\n",
      "\tmovq\t%rsi, %rsp\n",
      "\tincq\t%rcx\n",
      "\tmovq\t%rcx, -16(%rax)\n",
      "\tmovabsq\t$jl_bounds_error_ints, %rax\n",
      "\tmovl\t$1, %edx\n",
      "\tcallq\t*%rax\n",
      "\tnopl\t(%rax)\n"
     ]
    }
   ],
   "source": [
    "@code_native mysum(ones(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About global scope\n",
    "So what does the previous machine code actually mean? Well, in practise:\n",
    "\n",
    "A global variable might have its value, and therefore its type, change at any given point. This makes it difficult/nigh impossible for the compiler to reason about/optimize code using global variables.\n",
    "\n",
    "Julia uses functions as its compilation unit and any code that is performance critical or being benchmarked should be inside a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo: Giving hints to the compiler \n",
    "Let's see what we can do with our previously defined `laplacian` function. \n",
    "\n",
    "For some aggressive cases we can provide the JIT-compiler `@inbounds` macro hinting that there is no need to check array bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "laplacian_good (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets re-define our previous Laplacians (from 05_ notebook)\n",
    "function laplacian_bad(lap_x::Array{Float64,2}, x::Array{Float64,2})\n",
    "    nr,nc = size(x)\n",
    "    for ir = 2:nr-1, ic = 2:nc-1 # bad loop nesting order\n",
    "        lap_x[ir,ic] =\n",
    "            (x[ir+1,ic] + x[ir-1,ic] +\n",
    "            x[ir,ic+1] + x[ir,ic-1]) - 4*x[ir,ic]\n",
    "    end\n",
    "end\n",
    "\n",
    "#In this version, the two loops are nested properly:\n",
    "function laplacian_good(lap_x::Array{Float64,2}, x::Array{Float64,2})\n",
    "    nr,nc = size(x)\n",
    "    for ic = 2:nc-1, ir = 2:nr-1 # good loop nesting order\n",
    "        lap_x[ir,ic] =\n",
    "            (x[ir+1,ic] + x[ir-1,ic] +\n",
    "            x[ir,ic+1] + x[ir,ic-1]) - 4*x[ir,ic]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "laplacian_good_nocheck (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A way to increase the speed is to remove the array bounds checking, using the macro @inbounds:\n",
    "function laplacian_good_nocheck(lap_x::Array{Float64,2}, x::Array{Float64,2})\n",
    "    nr,nc = size(x)\n",
    "    for ic = 2:nc-1\n",
    "        for ir = 2:nr-1 # good loop nesting order\n",
    "            @inbounds begin lap_x[ir,ic] = # no array bounds checking\n",
    "                (x[ir+1,ic] +  x[ir-1,ic] +\n",
    "                x[ir,ic+1] + x[ir,ic-1]) - 4*x[ir,ic]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laplacian_bad:          2.758 s\n",
      "laplacian_good:         0.233 s\n",
      "laplacian_good_nockeck: 0.150 s\n"
     ]
    }
   ],
   "source": [
    "function main_test(nr, nc)\n",
    "    field = zeros(nr, nc)\n",
    "    for ic = 1:nc, ir = 1:nr\n",
    "        if ir == 1 || ic == 1 || ir == nr || ic == nc\n",
    "            field[ir,ic] = 1.0\n",
    "        end\n",
    "    end\n",
    "    lap_field = zeros(size(field))\n",
    "\n",
    "    time = @elapsed laplacian_bad(lap_field, field)\n",
    "    @printf \"laplacian_bad:          %.3f s\\n\" time\n",
    "    \n",
    "    time = @elapsed laplacian_good(lap_field, field)\n",
    "    @printf \"laplacian_good:         %.3f s\\n\" time\n",
    "    \n",
    "    time = @elapsed laplacian_good_nocheck(lap_field, field)\n",
    "    @printf \"laplacian_good_nocheck: %.3f s\\n\" time\n",
    "end\n",
    "\n",
    "main_test(10^4, 10^4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Threading (experimental)\n",
    "Julia threading model is based on a fork-join approach and is still considered experimental.\n",
    "\n",
    "Fork-join describes the control flow that a group of threads undergoes. Execution is then forked and an anonymous function is ran across all threads.\n",
    "\n",
    "All threads have to join together and serial execution continues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Threading in practise\n",
    "The number of threads Julia starts up with is controlled by an environment variable called `JULIA_NUM_THREADS`. Now, let's start up Julia with 4 threads:\n",
    "\n",
    "```bash\n",
    "export JULIA_NUM_THREADS=4\n",
    "julia\n",
    "```\n",
    "\n",
    "NOTE: this does not work in the notebook environment because the kernel is automatically loaded with only 1 thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Base.Threads\n",
    "nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using threads\n",
    "\n",
    "```julia\n",
    "@threads for id in 1:nthreads()\n",
    "    #each thread does something\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = zeros(10)\n",
    "@threads for i = 1:10\n",
    "    a[i] = Threads.threadid()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Advanced: Threaded sum\n",
    "Here is a more complex example of threaded sum from https://github.com/stevengj/18S096/blob/master/lectures/lecture5/Parallelism.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "threaded_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function threaded_sum(arr)\n",
    "   @assert length(arr) % nthreads() == 0\n",
    "    \n",
    "   let results = zeros(eltype(arr), nthreads())\n",
    "       @threads for tid in 1:nthreads()\n",
    "           # split work\n",
    "           acc = zero(eltype(arr))\n",
    "           len = div(length(arr), nthreads())\n",
    "           domain = ((tid-1)*len +1):tid*len\n",
    "           @inbounds for i in domain\n",
    "               acc += arr[i]    \n",
    "           end\n",
    "           results[tid] = acc\n",
    "       end\n",
    "       sum(results)\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributed computing \n",
    "Distributed processing uses individual processes that communicate with each other. In this case, data movement and communication is explicit!\n",
    "\n",
    "Julia supports various forms of distributed computing. \n",
    "- **A native master-worker system based on remote procedure calls**\n",
    "- MPI through [MPI.jl](https://github.com/JuliaParallel/MPI.jl)\n",
    "- [DistributedArrays.jl](https://github.com/JuliaParallel/DistributedArrays.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Master-Worker model\n",
    "NOTE: this does not work in the notebook environment. Instead, we need to launch Julia with \n",
    "```bash\n",
    "julia -p 4\n",
    "```\n",
    "then inside Julia you can check\n",
    "```julia\n",
    "nprocs()\n",
    "workers()\n",
    "```\n",
    "which should print `5` and `[2,3,4,5]`. \n",
    "\n",
    "Why 5, you ask? Because *\"worker 1\"* is the *\"boss\"*. And bosses don't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Functions (and everything used by workers) needs to be explicitly declared for all:\n",
    "```julia\n",
    "@everywhere g(x) = 2x\n",
    "```\n",
    "Only then can we send the job to somebody else to execute\n",
    "```julia\n",
    "remotecall_fetch(g, 3, 2.0)\n",
    "```\n",
    "Here we fetch the result of `g` of worker `3` applied to a value of `2.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use `@everywhere` to execute a top-level block on each process\n",
    "```julia\n",
    "@everywhere begin\n",
    "    using Test\n",
    "    include(\"src.jl\")\n",
    "end\n",
    "```\n",
    "Define variables on all processes\n",
    "```julia\n",
    "@everywhere bar = 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `@parallel` as a shortcut \n",
    "A parallel for loop of the form :\n",
    "```julia\n",
    "@parallel [reducer] for var = range\n",
    "    body\n",
    "end\n",
    "```\n",
    "The specified range is partitioned and locally executed across all workers. In case an optional reducer function is specified, @parallel performs local reductions on each worker with a final reduction on the calling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that without a reducer function, `@parallel` executes asynchronously, i.e., it spawns independent tasks on all available workers and returns immediately without waiting for completion. To wait for completion, prefix the call with `@sync`, like :\n",
    "```julia\n",
    "@sync @parallel for var = range\n",
    "      body\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "nheads = @parallel (+) for i=1:200000000\n",
    "  Int(rand(Bool))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## @pmap for unbalanced load\n",
    "In some cases no reduction operator is needed, and we merely wish to apply a function to all integers in some range. This is another useful operation called parallel map. \n",
    "\n",
    "For example, we could compute the singular values of several large random matrices in parallel as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "M = Matrix{Float64}[rand(1000,1000) for i=1:10]\n",
    "pmap(svd, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pmap()` is designed for the case where each function call does a large amount of work. In contrast, `@parallel for` can handle situations where each iteration is tiny, perhaps merely summing two numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary: General optimization tricks\n",
    "\n",
    "- write functions!\n",
    "- Avoid global variables\n",
    "    - A global variable might have its value, (and type) change at any given point. This makes it hard for the compiler to optimize."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
